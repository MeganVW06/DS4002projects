import pandas as pd


preambles = pd.read_csv("/Users/meganvanderwiele/Downloads/DS 4002/preambles_data.csv")


preambles.head(10)


preambles = preambles.rename(columns={'C ountry': 'Country', 'P reamble': 'Preamble'})[['Country', 'Preamble']]


preambles.head()






stop_words = set([
    "the", "and", "or", "for", "to", "of", "in", "on", "with", "at", "by", "from", "as", "an", "a", 
    "this", "that", "these", "those", "is", "was", "are", "were", "be", "been", "being", "it", "its", 
    "he", "she", "they", "them", "his", "her", "their", "we", "us", "our", "you", "your", "yours"
])

# function to remove stop words from preambles
def remove_stopwords(text):
    if isinstance(text, str):
        words = text.split()  #splits text into words
        filtered_words = [word for word in words if word.lower() not in stop_words]
        return ' '.join(filtered_words)
    return text

# Apply function to the 'Preamble' column
preambles['Preamble Cleaned'] = preambles['Preamble'].apply(remove_stopwords)



preambles.head(10)






preambles[['Country Name', 'Year']] = preambles['Country'].str.rsplit(' ', n=1, expand=True)

preambles = preambles[['Country Name', 'Year', 'Preamble', 'Preamble Cleaned']]
preambles.head()






import pycountry_convert as pc

def get_region(country_name):
    try:
        # Convert country name to ISO Alpha-2 code
        country_code = pc.country_name_to_country_alpha2(country_name)
        # Convert country code to region
        region_code = pc.country_alpha2_to_continent_code(country_code)
        # Map region codes to region names
        region_mapping = {
            "AF": "Africa",
            "AS": "Asia",
            "EU": "Europe",
            "NA": "North America",
            "SA": "South America",
            "OC": "Oceania",
            "AN": "Antarctica"
        }
        return region_mapping.get(region_code, "Unknown")
    except Exception:
        return "Unknown"

# Apply the function to the Country_Name column
preambles['Region'] = preambles['Country Name'].apply(get_region)


preambles.head()






#Graph showing how many preambles are in each region
import matplotlib.pyplot as plt
import seaborn as sns
countplot = sns.countplot(y='Region', data=preambles, order=preambles['Region'].value_counts().index)   
countplot.set_title('Number of Preambles in Each Region')
countplot.set_xlabel('Number of Preambles')
countplot.set_ylabel('Region')
plt.show()


preambles['Year'] = preambles['Year'].str.extract('(\d+)')
preambles['Year'] = preambles['Year'].astype(int)
#Graph showing how many preambles are in each 5 year period
preambles['Year Group'] = pd.cut(preambles['Year'], bins=range(1945, 2021, 5), right=False)
countplot = sns.countplot(y='Year Group', data=preambles, order=preambles['Year Group'].value_counts().index)
countplot.set_title('Number of Preambles in Each 5 Year Period')
countplot.set_xlabel('Number of Preambles')
countplot.set_ylabel('Year Group')
plt.show()


#find the most common words in the preambles
##this might not actaully be helpful at all but could be interesting to put in the presnetation as a more visual representation of the preambles
wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(' '.join(preambles['Preamble Cleaned'].astype(str)))
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud)
plt.axis('off')
plt.show()



#count the important words in the preambles from a predeetermined list
important_words = set([
    "peace", "security", "development", "human", "rights", "justice", "equality", "freedom", "democracy",]
) 
#now we will count the number of times each of these words appears in the preambles and save that as a new column
def count_important_words(text):
    if isinstance(text, str):
        words = text.split()
        count = sum(1 for word in words if word.lower() in important_words)
        return count
    return 0

preambles['Important Words Count'] = preambles['Preamble Cleaned'].apply(count_important_words)
preambles.head()


#graph that shows the number of important words in the preambles by region
countplot = sns.barplot(x='Important Words Count', y='Region', data=preambles, estimator=sum, ci=None)
countplot.set_title('Number of Important Words in Preambles by Region')
countplot.set_xlabel('Number of Important Words')
countplot.set_ylabel('Region')
plt.show()



#graph that shows the list of important words on the x axis and the number of times they appear in the preambles on the y axis
word_counts = {word: 0 for word in important_words}

for preamble in preambles["Preamble Cleaned"].dropna():
    for word in important_words:
        word_counts[word] += preamble.lower().count(word)

# bar chart 
plt.figure(figsize=(10, 6))
plt.bar(word_counts.keys(), word_counts.values())
plt.xlabel("Important Words", fontsize=14)
plt.ylabel("Count in Preambles", fontsize=14)
plt.title("Frequency of Important Words in Preambles", fontsize=16)
plt.xticks(rotation=45, fontsize=12)
plt.tight_layout()
plt.show()

